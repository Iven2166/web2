---
title: "读书笔记-推荐系统相关知识"
date: 2023-02-01
toc: true
categories:
  - reco
classes: wide
words_per_minute: 10
---

# 1. 推荐系统简介

推荐系统需要众多模块合作：
- 日志系统去收集用户交互数据，落原始数据
- 数据加工：大数据系统、流式计算系统加工数据
- 模型更新：在线学习，系统及时去更新模型
- 监控系统：有监控体系去定期反馈模型是否运行正常，能够自动报警
- AB系统：有完善的模型、算法、策略评估体系，能够逐步优化推荐系统

## 1.1 各环节

| 环节 | 量级 | 角色                                                                                                                                                                       |
|------|------|----------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| 召回 | 百万 | 在短时间内，从物料库内召回接近用户兴趣的物料（剔除离谱的物料）。 由于速度要求，以及量级巨大，所以精度不做太高要求，以多路召回来弥补。 主要依赖“离线缓存，在线索引”的操作。 |
| 粗排 | 万   | 处于召回和精排之间，在数据量、模型结构复杂程度，相对平衡。                                                                                                                 |
| 精排 | 千   | 由于量级较小，所以模型结构可以较复杂，对精度要求较高。 在推荐链路靠后，能够较大影响最终结果。                                                                              |
| 重排 | 几十 | 对于精排结果有可能集聚的情况，把相似内容进行打散，减少用户审美疲劳。                                                                                                       |

## 1.2 数据架构：lambda架构

- 实时数据流
  - 在线层：利用 storm、flink等流式计算框架，用户行为不等数据落地，就直接分析计算，计算结果缓存到redis
- 历史日志
  - 离线层：小时级别的定时任务，去回溯过去较长周期的用户行为日志。hadoop、spark
  - 近线层：HDFS读写效率低的介质，所以结果导入redis这种键值型数据库，加速访问

# 2. 特征工程

比如DIN模型能够从用户行为序列挖掘出用户的短期兴趣，SIM模型能够挖掘长期兴趣。但不意味着不需要对用户的历史行为做任何特征工程。因为一些复杂模型，耗时会和候选集的规模成正比，不好用在粗排或者召回里。

特征工程技巧，能够将计算压力从线上转移到线下，离线挖掘出用户的长短期兴趣，提供到召回、粗排里进行在线训练和预测使用。

## 2.1 物料画像

物料的属性：最基础、直接的信息。比如视频的作者、作者等级、粉丝量、标题和简介、上传时间、清晰度。比如电商里，商品的介绍、图片、视频、上传时间、商铺（等级、关注量、物品量）等特征。

物料唯一标识（item ID）也是极为重要的，模型记忆即可。作为类别特征，是高维、稀疏的。

- 物料的类别和标签：内容理解算法，去做物料的分类以及置信度
- 物料基于内容emb：emb表征物料的内容，增加类别标签以外的扩展性
- 物料的动态画像：**后验**统计数据，反应物料的受欢迎程度
  - 比如：不同时间粒度，不同类型的统计（CTR、CVR、平均播放时长、评论等）
  - 本质：是一个后验指标，只能说明我们推荐的效果好，但不意味着给当前这个用户推送就是好的。作为特征是有偏的。如果参与到精排，所谓的"幸存者偏差"还不会那么严重。
  - 马太效应问题：将后验数据作为特征，不利于新物料的冷启动。
- 用户给物料的标签：比如用户的消费标签的比重，来调整当前的物料。比如，球星的八卦新闻，我们初始打标为"体育"，但经常消费"娱乐"的用户来消费它比重较大，说明应该是物料应该是偏"娱乐"

## 2.2 用户画像

- 用户静态画像
  - 对于没什么行为的新用户不友好
    - 新老用户共用一个模型，老用户贡献的样本多，主导了训练模型，不容易学习到新用户相对友好的特征
  - UserID特征
    - 上亿用户情况下，采用 parameter server 分布式支持
    - 提供了最细粒度的个性化信息
- 用户动态画像
  - 通过用户一段时间里交互过的物料 Item ID 按时间序列进行集合，在放到模型里去提取用户的兴趣
  - 和物料相关的模型
    - 候选物料：attention pooling
    - 无候选物料：普通的 pooling
  - 缺点：如果将提取兴趣和CTR模型结合在一起，都必须在线上完成，特别是复杂模型DIN等，耗时会跟候选集规模成正比。但实际上我们是希望从历史序列里去做长行为序列里的用户兴趣。
    - 改进：将提取用户兴趣和CTR建模解耦。通过离线去计算用户兴趣，存储后用user id 去查询相应指标，耗时就可以减少。

## 2.3 交叉特征

- 笛卡尔积交叉：两个field内的feature进行两两组合，形成一个新的field
- 内积交叉：比如双塔模型里，用户和物料的交互

## 2.4 偏差特征

背景：我们用某个行为来衡量用户是否喜欢物料，比如点击代表喜欢。但有可能用户点击了未必喜欢，喜欢的未必去点击。**候选物料之间的评估环境，并非绝对公平的。** 最常见的就是位置偏差。另外，Youtube还发现视频生命周期带来的偏差（比如，视频长传久了，后验的消费指标，比如点击率、人均观看时长、总观看时长、总播放量）都会比较高，导致马太效应。

如何解决：
- 更严格的定义正负样本：限制在 点击物料上方的未点击物料，才作为负样本。防止曝光后，喜欢但是未点击的物料被错误地视为负样本。
- 模型去定义：
  - 将位置偏差作为特征加到模型里，在推理时都填为零（因为模型此刻并不知道视频排序，所以都视为第一个；同时，不应该让该特征影响了DNN模块的预测排序）
  - 训练时，位置偏差特征作为**伪特征值**，应该单独加入到最后的logit值里，而不是加到DNN，让DNN里的其他特征跟它交互。

<figure>
  <img src="{{ '/assets/images/reco-shitaxi-1.png' | relative_url }}" alt="xgboost"  class="center" style="max-height:600px; max-width:800px">
</figure>

## 2.5 数值特征处理

- 处理缺失值
- 标准化
- 数据平滑和消偏
- 分桶离散化

## 2.6 类别特征

**类别特征是推荐算法的一等公民**

线上工程偏爱于类别特征，因为类别特征非常稀疏，可以实现非零存储，减少线上开销。以逻辑回归 LR 为例， $$ logit = b + sum(w_{j} * x) $$ 如果是类别型特征（0/1），则相加即可。如果是数值型特征，则需要很多乘法运算。

- 单个类别表达能力可能较弱：使用emb扩展其代表的语义
- 多特征交叉：将多个类别型特征进行交叉，能够生成新的表示
- 类别特征稀疏，罕见特征如何可能训练不充分——FTRL优化算法，自适应地调节学习率，常见的特征受训机会多，则步长减少一些；罕见特征受训机会少，则步长调整大一点。

# 3. emb

文章先引入了 LR 这个模型，特点在于强于记忆，能够记得历史上发生过的所有特征和组合。
- 所有模式，都依赖于人工的输入。
- 不能发掘出新模式，只能评估各个模式的重要性
- 强于记忆，弱于扩展

推荐算法不能仅满足于常见的模式（高频、常见），而是应该挖掘出来训练数据内罕见、低频、长尾的模式，才可以提升业务效果。

如果罕见的模式，去依靠人工去进行特征组合挖掘，必定会有局限，并且成本较大。

因此，有emb的概念引入。

## 3.1 共享还是独占emb

emb 实现较为简单，是随机化矩阵，每一行对应一个类别特征，然后用 SGD 随着模型一同优化。区别在于共享还是独占。

- 共享emb：能够缓解特征稀疏、训练数据不足的情况；另外是节省存储空间。比如FM算法，每个特征跟其他特征产生交叉时，运用的是唯一的emb。
- 独占emb：在不同业务领域的交互里，将同一个物料的emb进行隔离。比如下载和卸载同一个app的物料emb用不同的表示。

2021年，阿里的 Co-Action Network （CAN）利用不同的weight进行特征的交叉。

## 3.2 parameter server

简述：PS 是一个key-value的数据库形式，应对于 Master/Slave架构，大规模分布式训练时的困难。特征、emb维度非常高（可能到亿级别），无法在一个单机上装在，而是分布在集群里。

- worker：多个worker节点，会从server拉取（pull）模型参数，进行数据训练，给server推送（push）梯度
- server：多个server节点，每个节点只负责处理其中的一部分（shard）；面对pull 请求，会将最新的参数值发送回去；面对 push 请求，会聚合各个worker发送过来的梯度，通过SGD算法（Adam、Adagrad）更新模型参数
- scheduler：负责整个PS集群的管理，比如接受新节点的注册，将pull请求路由到合适的server节点

# 4. 精排

推荐算法模型的维度：
- 记忆和扩展：除了能够记忆高频、常见的模式，还能够扩展到长尾、低频的模式
- embedding：从"精确匹配"到"基于向量的模糊查找"，提升模型的扩展能力
- 高维稀疏的类别特征：parameter server 来分布式训练；平衡各个稀疏特征受训机会不均衡的问题；用emb进行扩展
- 交叉结构
- 用户行为序列建模

## 4.1 交叉结构

### LR 及 FTRL

（1）LR

在传统的 LR 逻辑回归算法里，特征以类别特征为主，所以 $x_i$ 为 0/1 

- LR类似于评分卡，将所有特征的重要性记忆，然后再看当前用户、物料、场景等命中了什么特征，再进行权重求和，得到排序得分。
- 模型侧不会进行特征交叉，扩展能力较弱

在线学习：用户在app的动作，触发后台服务向排序服务发送请求，包括了用户信息、候选物料的信息；排序服务，通过排序模型，打分后排序，返回结果给用户；同时，用户反馈、特征都返回给拼接服务，给训练服务trainer进行新样本下的模型更新。

所以，模型参数要尽可能稀疏，将非常高维度的特征里，不重要的置为0，让评分卡减少模型体积。

（2）FTRL（follow the regularized leader）

思想：
- 为了减少单个样本的抖动，不是单纯最小化第t步的损失，而是让之前所有步骤的损失之和最小，以及增加正则项
- 特殊正则：老模型和新模型的参数 w 之间的距离不能扩大果园，否则相当于一味地迎合新样本
- 给每个特征设立步长：在样本里频繁出现的特征所贡献的梯度，放在步长的表达式的分母位置，所以越频繁的步长越小。

### FM

FM 相比 LR 增加了二阶特征交叉，但改写为每个特征有自己的emb，交互时通过emb交互

效果：
- 二阶特征交叉学习参数从 $n^2$ 下降到 $n k$ , k 是特征emb的长度
- 只要 x 不为0，则能够训练 对应的emb。（原有的操作，依赖于交叉的两个特征均不是0）

### wide & deep
 google 于 2016年提出
 
- deep侧：类别特征转化为 emb，输入DNN模型结构，进行高阶隐式交叉
- wide侧：LR的算法，发挥记忆的优势，对于高频出现的模式友好。另外，防止deep侧过度扩展从而影响预测精度，起到类似正则化的作用。

训练的时候，预测结果是两边的logit相加，经过sigmoid。优化时（梯度下降），wide侧为了保持稀疏性，利用FTRL优化器；deep侧是DNN的常规优化器，比如 adagrad、adam等

### DeepFM：融合二阶交叉

$$ logit_{dnn} = DNN(concat(embedding(x_{dnn}))) $$

$$ logit_{fm} = FM(x_{fm},concat(embedding(x_{fm}))) $$

$$ logit_{lr} = w_{lr} * x_{lr} $$

$$ CTR_{predict} = sigmoid(logit_{dnn} + logit_{fm} + logit_{lr}) $$

### DCN: deep & cross network

实现特征交叉，仅依靠DNN这种隐式交叉是不够的，还需要加上 显式、指定阶数的交叉作为补充。

$$ x_{l+1} = x_{0} x_{l}^{T} w_{l} + b_{l} + x_{l}$$

- $x_{0}$ 是最低下一层 cross layer 的输入，有各种类别特征的 embedding 和稠密特征拼接而成，是长度为 d 的稠密浮点数向量。
- $x_{l}$ $x_{l+1}$ 是第 l 层的输入和输出，学习到 $w_{l}$ 和 $b_{l}$ 参数

### AutoInt：attention 的结构

## 4.2 用户行为序列建模

用户行为序列（点击、观看、购买等序列），我们讨论将一个行为序列进行压缩，成为代表用户兴趣的embedding的方法。

### 行为序列信息的构成

行为序列信息的构成，以观看视频为例。
- 每个视频id的emb得到的向量
- 时间差信息：保存观看某视频的时刻距离本次请求的时间差，再分桶为一个整数，这个桶应该是对应一个emb。我们一般默认，用户兴趣跟更近的更相关。让模型去刻画时间衰减。
- 还可以加入其他视频的信息（分类、标签等），以及行为的程度（观看时长，观看完整度）

### 简单pooling

将用户的行为序列压缩为一个兴趣向量，最简单操作是 池化操作（平均、max、取加权平均）

但简单的池化，实际上是一个固定的表示，它和当前要消费的候选物料没有直接的计算关系。所以对于精排而言，简单池化可能是不足的。对于召回而言，由于前置没有拿到候选物料信息，提取用户兴趣时，简单池化还是常规操作。

### DIN模型

阿里妈妈在 2018 年提出的 Deep Interest Network （DIN） 借鉴了 attention，实现了 "千物千面" 的效果（来了不同的候选集，模型关注度是不同的）

### 建模序列内的依赖关系

DIN模型能够体现用户兴趣的"千物千面"，捕捉的是候选物料和过去的用户序列元素的交叉，但没法捕捉用户序列内的各元素的依赖交叉关系。

目前常用的建模用户行为序列的方法是采用双层 attention，实际上就是把用户行为序列作为seq，输入到（多层）的transformer的encoder里，去做各个行为的多头注意力机制。比如浏览过 "妇联" 和 "美国队长"，通过注意力机制交叉出来的就是一个喜欢美国英雄系列的用户。

### 建模长序列

长序列在推理预测时会代表更大的计算量和线上返回结果时间压力。

比如用户行为序列是 L，每个token的emb维度是 d，batch大小是 B

- DIN：我们拿候选物料当作query去对整个序列做attention时，时间复杂度 = $O(B \times L \times d)$
- 双层attention：序列的内部做 self-attention 时间复杂度 = $O(B \times L^{2} \times d)$，跟用户行为序列实际上是平方关系

（1）在线提取用户兴趣

阿里妈妈 search-based interest model （SIM）

- 现状：DIN是拿候选集对行为序列做attention，学习跟历史物料的关系权重，类似于"软过滤"
- 改变：在长序列里筛选出跟候选物料相关的短序列（一般长度在 百 级别），称为 sub user behavior sequence （SBS）。由于长度缩短，就可以再套用DIN，加权平均后的结果就是用户长期兴趣的向量表达。

搜索的方式：
- hard search：拿候选物料的某个属性（物料分类、标签等），在用户完整的长期历史里搜索与其有相同属性的历史物料。在实际实现里，是缓存起来。哈希表的层级是， 用户-属性-该属性下的近期行为序列
- sort search：在用户长期行为序列里，通过"近似近邻居搜索算法"（ANN）去查找与之距离最近的前k个历史物料

（2）离线预训练用户兴趣

# 5. 召回

## 5.1 传统召回算法

### 基于物料属性的倒排索引

存储 Map<Item attribute, Item set> 数据结构，倒排索引

线上来一个用户请求，提取用户喜欢的标签、关注的作者等信息，再按照检索倒排索引，把对应的物料集合作为召回结果返回。

### 基于统计的协同过滤算法

传统的协同过滤，无需训练模型。

- 基于用户的协同过滤（User CF）
- 基于物料的协同过滤（Item CF）

### 矩阵分解算法

### 如何合并多路召回

如果合并的结果集合太大，超出下游粗精排的处理能力，需要截断。

人为给各路召回指定一个插入顺序，如果召回队列还有余量时，前面的召回把结果集插满了，插满了返回。

## 5.2 向量化召回统一建模框架

向量化召回，就是把召回问题，建模为向量空间内的近邻检索问题。

- Q：query 
- T：target

- 训练模型，将Q、T映射到同一个向量空间里
- 将 T 用模型推理，映射为向量，放到FAISS向量数据库里
- 在线服务，来了一个Q，将其映射为向量，通过近似近邻搜索（ANN）算法，将最近的k个T类的邻居向量作为召回结果返回。

### 正样本（类似的）

- 用户在同一个session（会话，交互时间间隔较短）里，交互过的两个物料，在向量空间里是相近的
- 用户和物料交互过，说明用户和物料是相近的

### 负样本

要让模型"见多识广"，学习到五花八门的差异性。


