---
title: "NLP-query预测"
date: 2023-06-01
toc: true
categories:
  - content-nlp
classes: wide
words_per_minute: 10
sidebar:
  - nav: "nlp_docs"
---

类目预测query相关性，保证商品召回的相关性，提升用户的搜索体验。但针对搜索query的类目预测存在较多的问题：

1. query长度较短，包含信息太少。

2. 一个query往往不一定只与一个类目相关，其可能与多个类目相关

3. 长尾搜索query较多，较难统计归类

4. 类目上流量马太效应严重，存在较多类目流量较少。

5. 类目一般分为多级，越靠近叶子节点，预测难度越大。同时，类目的叶子节点可能有数十万个。

6. 类目间存在重叠情况，本身区分难度较大。例如毛衣和针织衫


## 业务信息

- 类目体系：前台类目：和营销相关，可能经常会变。后台类目：将商品、物料等进行挂钩，不会经常变化；应该是分类的重点。做法是，预测后台类目，解耦地让前台类目链接到后台类目
- 其他预测：标签体系、属性体系

## 可能的预测任务

- 多级、多标签的分类任务
  - 将所有叶子节点标签拉齐后的分类
  - 分级别地建立模型，让更深叶子节点的预测具备前一个层级的预测信息
- 文本匹配任务：将query和类目体系进行相似度计算
- 无监督：通过query和物料出现的共现情况进行计算，进行聚类


## 具体模块

### 样本准备

一般的做法是选择一段时间的搜索点击日志（比如最近3个月或者半年），然后可以得到query点击doc的数据 query-clk_doc（也可以选择购买行为，但是数据会更稀疏）。再根据doc挂载的类目标签从而得到query到类目标签的数据 query-category。按照query维度进行聚合，得到query在类目的分布情况。最后选择top1的类目当作该query的类目标签，从而得到最终的训练样本 (query, category)。

### 任务模型

采用弱监督的形式，先构造预训练模型。引入业界已有一定权重的预训练模型。
- 进行领域内预训练：使用query与doc的数据继续进行语言模型的继续预训练。预训练任务可以自行选择，比如常见的 MLM（Masked Language Model）、RTD（Replace Token Detection）等。领域内持续预训练是一个很划算的任务，因为得到的模型在下游多个任务均可使用，而且对下游任务的提升效果很显著。
- 任务适配预训练：在微调步骤前，可以通过构造一个和下游任务比较贴合的伪任务让encoder层学习到更丰富的语义信息。这里介绍一种弱监督任务作为类目预测的任务适应型预训练任务。在搜索场景下我们可以通过搜索日志得到大量的 (query-点击title)的数据，利用这些数据我们可以构造一个双句分类任务。正样本就是高点击的，负样本可以采用随机采样的策略。另一种构建高难度负样本的方法是对query-点击title列表进行排序，靠前的当作正样本，中部的当作负样本，排序因子可以简单选择威尔逊分数。




参考[知乎1]、[知乎2]



[知乎1]:https://zhuanlan.zhihu.com/p/565229684
[知乎2]:https://zhuanlan.zhihu.com/p/90923697